코드 동작 방법
1. Make_sound 파일을 실행시켜 Data 폴더 안에 Test2_sound 파일을 생성시킵니다.
2. Make_xyz 파일을 실행시켜 Data 폴더 안에 Test2_xyz 파일을 생성시킵니다.
3. eda_ecg_find_peaks 파일을 실행시켜 Data 폴더 안에 ecg_find_private_test_30min 파일을 생성합니다.
4. eda_ecg 파일을 실행해 Data 폴더 안에 best-of-best-ecg-private-test 파일을 생성합니다.
5. main_model 파일을 실행시켜 학습을 진행한 뒤, Test 데이터에 대해 예측을 진행합니다.
6. 예측의 결과로 Test2.csv파일이 생성됩니다.



소리 데이터 처리:
    한 채널 안에서 500개씩 클러스터링하여 새로운 배열 a로 저장합니다.
    이 과정을 20개 채널에서 반복합니다.
    그 후 각 배열 a에서의 i번째 인자와 i+1번째 인자의 차이가 표준편차보다 큰 비율을 계산하여
    한 사람당 (1, 20)의 배열을 만듭니다.
    
가속도 데이터 처리:
    가속도 데이터도 소리 데이터와 동일하게 처리하였습니다.
    각 축 값을 합하여 하나의 스칼라 값으로 만든 후
    각 배열에서의 i번째 인자와 i+1번째 인자의 차이가 표준편차보다 큰 비율을 계산하여
    한 사람당 (1, 시간)의 배열을 만듭니다.

ECG 데이터 처리:
    EDF파일을 불러올 때 사용한 MNE프레임워크에서 제공하는 R피크 찾는 함수를 이용하여 피크를 찾았습니다.
    이후 피크 간의 인터벌인 RR Interval을 구하였습니다.
    데이터가 정확하지 않기에 여러 논문들을 참고하여 RR Interval값을 보정하였습니다.

모델 학습 과정:
    기본적으로 소리 데이터를 이용하여 1D CNN으로 학습을 진행하였습니다.
    OSA환자의 경우 평균적으로 소리 데이터값이 일반인보다 크기에 이 특성을 이용하여 학습을 진행할 수 있을 것이라 생각하였습니다.
    그런데 OSA환자 중에서도 소리값이 작은 환자들이 있었습니다.
    이를 어떻게 처리할까 고민하던 중 소리값이 작은 환자들의 ECG값의 변동폭이 큰 것을 관찰하였습니다.
    그래서 ECG값의 변동폭이 크고 가속도값이 작은 케이스는 소리 데이터값을 증폭시켜주었습니다.
    이후 CNN을 이용하여 학습을 진행하였습니다.

